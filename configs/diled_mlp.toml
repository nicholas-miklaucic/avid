batch_size = 64
do_profile = false
num_epochs = 100
regressor = "vit"
task = "diled"

[voxelizer]
max_unique_species = 5
n_grid = 24
distance_power = 2.0
eff_scale = 0.7
num_cells = 4

[data]
dataset_name = "jarvis_dft3d_cleaned"
raw_data_folder = "data"
data_folder = "precomputed"
shuffle_seed = 1618
train_split = 20
test_split = 1
valid_split = 4
do_augment = false
augment_seed = 12345
so3 = true
o3 = true
t3 = true

[data_transform]
density_transform_name = "log"
density_scale = 0.25
density_shift = 1
eps = 1e-12

[cli]
verbosity = "info"
show_progress = true

[device]
device = "gpu"
max_gpus = 1
gpu_ids = []

[log]
log_dir = "logs"
logs_per_epoch = 8

[train]
lr_schedule_kind = "cosine"
start_lr_frac = 0.1
base_lr = 0.004
end_lr_frac = 0.04
weight_decay = 0.03
beta_1 = 0.9
beta_2 = 0.999
nestorov = true
max_grad_norm = 3.0

[diled]
patch_latent_dim = 256
patch_conv_sizes = [3]
patch_conv_strides = [3]
patch_conv_features = [32]
use_dec_conv = false
species_embed_dim = 96
species_embed_type = "ortho"
w = 0

[diled.backbone]
condition_mlp_dims = [128]
time_dim = 64
label_dim = 64
condition_dropout = 0.0

[diled.diffusion]
schedule_a = 1.7
schedule_b = 1.9
timesteps = 100
class_dropout = 0.5

[diled.category]
category_loss_type = "cubic_space_group"

[diled.encoder]
num_layers = 1
num_heads = 8
enc_dropout_rate = 0.1
enc_attention_dropout_rate = 0.1
equivariant = true
encoder_type = "mlp"

[diled.head]
inner_dims = [1024, 512]
activation = "gelu"
final_activation = "Identity"
dropout = 0.5
equivariant = false

[diled.perm_head]
inner_dims = [512]
activation = "gelu"
final_activation = "Identity"
dropout = 0.3
num_heads = 1
equivariant = false

[diled.backbone.time_mlp]
inner_dims = []
activation = "gelu"
final_activation = "Identity"
dropout = 0.1
equivariant = false

[diled.backbone.encoder]
num_layers = 2
num_heads = 16
enc_dropout_rate = 0.1
enc_attention_dropout_rate = 0.1
equivariant = true
encoder_type = "mlp"

[diled.encoder.mlp]
inner_dims = []
activation = "gelu"
final_activation = "Identity"
dropout = 0.1
equivariant = false

[diled.encoder.token_mixer]
inner_dims = []
activation = "gelu"
final_activation = "Identity"
dropout = 0.1
num_heads = 16
equivariant = false

[diled.backbone.encoder.mlp]
inner_dims = []
activation = "gelu"
final_activation = "Identity"
dropout = 0.1
equivariant = false

[diled.backbone.encoder.token_mixer]
inner_dims = []
activation = "gelu"
final_activation = "Identity"
dropout = 0.1
num_heads = 16
equivariant = true
